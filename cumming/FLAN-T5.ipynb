{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff949ddf-170e-4b48-af2d-b45123c5a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 4.57.3\n",
      "peft version: 0.18.0\n",
      "device: cuda\n",
      "Loaded examples: 9741\n",
      "Example raw row: {'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?', 'choices': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid'], 'answer': 'A', 'short_explanation': 'Because \"ignore\" best shows the sanctions disregarded the school\\'s efforts to change.'}\n",
      "Processed examples: 9741\n",
      "question: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "choices: A: ignore; B: enforce; C: authoritarian; D: yell at; E: avoid\n",
      "explain your answer:\n",
      "answer: A. Because \"ignore\" best shows the sanctions disregarded the school's efforts to change.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "print(\"transformers version:\", __import__(\"transformers\").__version__)\n",
    "print(\"peft version:\", __import__(\"peft\").__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# 1) load data from jsonl\n",
    "data_path = \"csqa_full_clean_v2.jsonl\"\n",
    "\n",
    "rows = []\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        rows.append(json.loads(line))\n",
    "\n",
    "print(\"Loaded examples:\", len(rows))\n",
    "print(\"Example raw row:\", rows[0])\n",
    "\n",
    "\n",
    "def clean_explanation(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = text.replace(\"```\", \"\").replace(\"`\", \"\")\n",
    "    text = re.sub(\n",
    "        r\"\\bplaintext\\b|\\bpython\\b|\\bjson\\b|\\btext\\b\",\n",
    "        \"\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE,\n",
    "    )\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"^(Because\\s+)+\", \"Because \", text, flags=re.IGNORECASE)\n",
    "    if text and not text.endswith(\".\"):\n",
    "        text += \".\"\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def format_choices(choice_list):\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "    return \"; \".join(\n",
    "        f\"{letters[i]}: {choice_list[i]}\" for i in range(len(choice_list))\n",
    "    )\n",
    "\n",
    "\n",
    "processed = []\n",
    "for ex in rows:\n",
    "    q = ex[\"question\"]\n",
    "    choices = ex[\"choices\"]\n",
    "    ans = ex[\"answer\"]              # \"A\" / \"B\" / ...\n",
    "    expl = clean_explanation(ex.get(\"short_explanation\", \"\"))\n",
    "\n",
    "    input_text = (\n",
    "        f\"question: {q}\\n\"\n",
    "        f\"choices: {format_choices(choices)}\\n\"\n",
    "        f\"explain your answer:\"\n",
    "    )\n",
    "    target_text = f\"answer: {ans}. {expl}\"\n",
    "\n",
    "    processed.append(\n",
    "        {\n",
    "            \"input_text\": input_text,\n",
    "            \"target_text\": target_text,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Processed examples:\", len(processed))\n",
    "print(processed[0][\"input_text\"])\n",
    "print(processed[0][\"target_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9aadc14-9303-4b6f-9799-d3b65ead42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 9741 train: 7792 val: 1949\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_list(processed)\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "val_dataset = dataset.select(range(train_size, total_size))\n",
    "print(\"total:\", total_size, \"train:\", len(train_dataset), \"val:\", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65057d51-b9f4-40b6-9903-56e742e244d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2adc36d6c91461bb6a94f6509050969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\py\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd862ca3f0445e5b329b9f8062c8c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7792 1949\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "model_name = \"google/flan-t5-base\"   # CHANGED: use FLAN-T5-base\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_input_length = 384\n",
    "max_target_length = 96\n",
    "\n",
    "\n",
    "def basic_clean(t: str) -> str:\n",
    "    if t is None:\n",
    "        return \"\"\n",
    "    t = str(t)\n",
    "    t = t.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    return t.strip()\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    input_text = basic_clean(example[\"input_text\"])\n",
    "    target_text = basic_clean(example[\"target_text\"])\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        input_text,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            target_text,\n",
    "            max_length=max_target_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "train_tokenized = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=False,\n",
    "    remove_columns=train_dataset.column_names,\n",
    ")\n",
    "val_tokenized = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=False,\n",
    "    remove_columns=val_dataset.column_names,\n",
    ")\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_tokenized.set_format(type=\"torch\", columns=cols)\n",
    "val_tokenized.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "print(len(train_tokenized), len(val_tokenized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e36b23-eb00-4db2-b141-6a85acba98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 249,347,328 || trainable%: 0.7096\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    task_type=\"SEQ_2_SEQ_LM\",   # keep exactly as in your old code\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73330ce5-201e-485e-b670-a3570c9173e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanch\\AppData\\Local\\Temp\\ipykernel_61640\\4230611125.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./flan_t5_base_csqa_lora_v2\",  # new name to avoid overwrite\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "\n",
    "    learning_rate=5e-5,        # CHANGED: smaller LR than 2e-4\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    fp16=False,                # keep fp16 off, same as old code\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3aa392f-c298-4cb8-a4d7-b931ce6a98b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\py\\Lib\\site-packages\\transformers\\data\\data_collator.py:740: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1461' max='1461' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1461/1461 1:14:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>40.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>37.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>28.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>16.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.814700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.494800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.477900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.722100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.480600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.343200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.062900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.993500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.920900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.886200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.881100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.863700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.851500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.844900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.870100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=1461, training_loss=5.766903509757521, metrics={'train_runtime': 4471.7021, 'train_samples_per_second': 5.228, 'train_steps_per_second': 0.327, 'total_flos': 1.2100466664013824e+16, 'train_loss': 5.766903509757521, 'epoch': 3.0})\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "print(train_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98e3a622-4ebc-47f2-8b88-6ee6f436dfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 validation examples (sampled from 1949)\n",
      "Validation accuracy on 200 examples: 0.6450 (64.50%)\n",
      "================================================================================\n",
      "Validation example 0\n",
      "Correct answer: E\n",
      "Predicted: E\n",
      "RIGHT ✓\n",
      "\n",
      "INPUT:\n",
      "question: Danny needed a new mouse, his was jumping around whenever he moved it. Where might his mouse be?\n",
      "choices: A: abandoned houses; B: corn field; C: cupboard; D: cabinet; E: desktop\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: E. Because a desktop allows for a mouse's typical use and movement, making E the correct answer.\n",
      "\n",
      "PREDICTION:\n",
      "answer: E. Because Danny needed a new mouse.\n",
      "\n",
      "================================================================================\n",
      "Validation example 1\n",
      "Correct answer: A\n",
      "Predicted: A\n",
      "RIGHT ✓\n",
      "\n",
      "INPUT:\n",
      "question: Who can have the most influence on washington from a given county?\n",
      "choices: A: representative; B: cleverest; C: bitterest; D: alter; E: sweet\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: A. Because representatives have formal channels to influence federal legislation, making A the correct choice.\n",
      "\n",
      "PREDICTION:\n",
      "answer: A. Because representative can have the most influence on washington from a given county.\n",
      "\n",
      "================================================================================\n",
      "Validation example 2\n",
      "Correct answer: A\n",
      "Predicted: C\n",
      "WRONG ✗\n",
      "\n",
      "INPUT:\n",
      "question: The brothers were punching angrily, why would they do that?\n",
      "choices: A: cause pain; B: to defend themselves.; C: broken bones; D: bruise; E: pain for\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: A. Because the brothers punched angrily to cause pain reflecting their aggressive state.\n",
      "\n",
      "PREDICTION:\n",
      "answer: C. Because punching angrily causes pain.\n",
      "\n",
      "================================================================================\n",
      "Validation example 3\n",
      "Correct answer: E\n",
      "Predicted: E\n",
      "RIGHT ✓\n",
      "\n",
      "INPUT:\n",
      "question: What does the D in DRC stand for?\n",
      "choices: A: dictatorship; B: democracy; C: democracy; D: state; E: democratic\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: E. Because \"Democratic\" in DRC indicates the government's republican and people-oriented ideals.\n",
      "\n",
      "PREDICTION:\n",
      "answer: E. Because D stands for democratic state.\n",
      "\n",
      "================================================================================\n",
      "Validation example 4\n",
      "Correct answer: B\n",
      "Predicted: D\n",
      "WRONG ✗\n",
      "\n",
      "INPUT:\n",
      "question: Becoming inebriated leads to what state?\n",
      "choices: A: regret; B: drunkenness; C: high energy; D: paralysis; E: arrest\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: B. Because \"drunkenness\" precisely describes the state of inebriation caused by alcohol consumption.\n",
      "\n",
      "PREDICTION:\n",
      "answer: D. Because drunkenness is a state of inebriation.\n",
      "\n",
      "Saved CSV to: ./flan_t5_base_csqa_lora_v2\\validation_sample_outputs.csv\n",
      "Saved JSONL to: ./flan_t5_base_csqa_lora_v2\\validation_sample_outputs.jsonl\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "model.eval()  # eval mode\n",
    "\n",
    "\n",
    "def extract_answer(pred_text: str):\n",
    "    \"\"\"\n",
    "    Extract choice letter (A-F) from model prediction.\n",
    "    Looks for patterns like 'answer: B', 'answer B.', etc.\n",
    "    \"\"\"\n",
    "    text = pred_text.strip().lower()\n",
    "    m = re.search(r\"answer[: ]*\\s*([a-f])\", text)\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Sample up to 200 examples from validation set\n",
    "# =========================\n",
    "\n",
    "val_size = len(val_dataset)\n",
    "n_eval = min(200, val_size)\n",
    "\n",
    "indices = list(range(val_size))\n",
    "random.seed(42)  # for reproducibility\n",
    "sample_indices = random.sample(indices, n_eval)\n",
    "\n",
    "# local indices in val_dataset -> global indices in rows\n",
    "# val_dataset 是 dataset[train_size:] 那一段\n",
    "global_indices = [train_size + i for i in sample_indices]\n",
    "\n",
    "subset = val_dataset.select(sample_indices)\n",
    "subset_list = list(subset)\n",
    "\n",
    "print(f\"Using {n_eval} validation examples (sampled from {val_size})\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Run model, compute accuracy, collect predictions\n",
    "# =========================\n",
    "\n",
    "results = []  # will store dicts\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ex, g_idx in zip(subset_list, global_indices):\n",
    "        # correct answer comes from original rows\n",
    "        gold_answer = rows[g_idx][\"answer\"]  # \"A\", \"B\", ...\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            ex[\"input_text\"],\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=max_input_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        gen_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"].to(device),\n",
    "            max_length=max_target_length,\n",
    "            num_beams=4,\n",
    "        )\n",
    "        pred_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "        pred_ans = extract_answer(pred_text)\n",
    "\n",
    "        is_correct = (pred_ans == gold_answer)\n",
    "\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"input_text\": ex[\"input_text\"],\n",
    "                \"target_text\": ex[\"target_text\"],\n",
    "                \"correct_answer\": gold_answer,\n",
    "                \"predicted_answer\": pred_ans,\n",
    "                \"prediction_text\": pred_text,\n",
    "                \"is_correct\": is_correct,\n",
    "            }\n",
    "        )\n",
    "\n",
    "accuracy = correct / n_eval if n_eval > 0 else 0.0\n",
    "print(f\"Validation accuracy on {n_eval} examples: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Show first few examples with predictions\n",
    "# =========================\n",
    "\n",
    "num_show = 5\n",
    "\n",
    "for i, rec in enumerate(results[:num_show]):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Validation example {i}\")\n",
    "    print(f\"Correct answer: {rec['correct_answer']}\")\n",
    "    print(f\"Predicted: {rec['predicted_answer']}\")\n",
    "    print(\"RIGHT ✓\" if rec[\"is_correct\"] else \"WRONG ✗\")\n",
    "\n",
    "    print(\"\\nINPUT:\")\n",
    "    print(rec[\"input_text\"])\n",
    "\n",
    "    print(\"\\nTARGET:\")\n",
    "    print(rec[\"target_text\"])\n",
    "\n",
    "    print(\"\\nPREDICTION:\")\n",
    "    print(rec[\"prediction_text\"])\n",
    "    print()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Save these 200 (or fewer) results to CSV and JSONL\n",
    "# =========================\n",
    "\n",
    "try:\n",
    "    out_dir = trainer.args.output_dir\n",
    "except NameError:\n",
    "    out_dir = \"./flan_t5_base_csqa_lora_v2\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(out_dir, \"validation_sample_outputs.csv\")\n",
    "jsonl_path = os.path.join(out_dir, \"validation_sample_outputs.jsonl\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(csv_path, index=False)\n",
    "print(\"Saved CSV to:\", csv_path)\n",
    "\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in results:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Saved JSONL to:\", jsonl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6ea59a8-9a94-4513-9582-5da8c9fa6d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Loading base model and LoRA checkpoint...\n",
      "Loaded model from ./flan_t5_base_csqa_lora_v2/checkpoint-1461\n",
      "Loading CoS-E v1.11 dataset...\n",
      "Example raw sample:\n",
      "{'id': '6b819727eb8a670df26a7ffad036c119', 'question': '\"There are 10 apples on an apple tree.  Three fall off.  Now there are X apples.\"  What is this an example of?', 'choices': ['park', 'coloring book', 'garden center', 'math problem', 'gravity'], 'answer': 'math problem', 'abstractive_explanation': 'webmath is designed to help you solve', 'extractive_explanation': '\"there are 10 apples on an apple tree. three fall off. now there are x apples.\" what is this an example of?'}\n",
      "Building MC version...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4474a7e69c4d46fe88682f44140e660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a00d759fce40cbb91f60794647c4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e50fc2fe2e4480856fd73276be4727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7b1249e45f4c82acfa59bc0c00e742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example MC sample:\n",
      "{'id': '6b819727eb8a670df26a7ffad036c119', 'question': '\"There are 10 apples on an apple tree.  Three fall off.  Now there are X apples.\"  What is this an example of?', 'choices': ['park', 'coloring book', 'garden center', 'math problem', 'gravity'], 'answer': 'math problem', 'abstractive_explanation': 'webmath is designed to help you solve', 'extractive_explanation': '\"there are 10 apples on an apple tree. three fall off. now there are x apples.\" what is this an example of?', 'answer_idx': 3, 'valid': True}\n",
      "Validation MC size: 1221, evaluating on 200 examples\n",
      "\n",
      "CoS-E v1.11 validation accuracy on 200 examples: 0.4800 (48.00%)\n",
      "================================================================================\n",
      "CoS-E example 0\n",
      "Correct letter: D\n",
      "Predicted letter: D\n",
      "RIGHT ✓\n",
      "\n",
      "QUESTION:\n",
      "At a grocery store they sell individual potatoes, where does the grocery clerk likely put the potato?\n",
      "\n",
      "CHOICES:\n",
      "  A: boiling water\n",
      "  B: root cellar\n",
      "  C: rocket ship\n",
      "  D: paper bag\n",
      "  E: underground\n",
      "\n",
      "PREDICTION TEXT:\n",
      "answer: D. Because the grocery clerk likely puts the potato in a paper bag.\n",
      "\n",
      "================================================================================\n",
      "CoS-E example 1\n",
      "Correct letter: E\n",
      "Predicted letter: C\n",
      "WRONG ✗\n",
      "\n",
      "QUESTION:\n",
      "The potato might be the official vegetable of what?\n",
      "\n",
      "CHOICES:\n",
      "  A: vegans\n",
      "  B: kitchen cupboard\n",
      "  C: restaurants\n",
      "  D: chicken\n",
      "  E: maryland\n",
      "\n",
      "PREDICTION TEXT:\n",
      "answer: C. Because potatoes are the official vegetable of Maryland.\n",
      "\n",
      "================================================================================\n",
      "CoS-E example 2\n",
      "Correct letter: A\n",
      "Predicted letter: A\n",
      "RIGHT ✓\n",
      "\n",
      "QUESTION:\n",
      "If a court case is dismissed after hearing testimony, what would be a likely cause?\n",
      "\n",
      "CHOICES:\n",
      "  A: change of heart\n",
      "  B: anguish\n",
      "  C: anger\n",
      "  D: boredom\n",
      "  E: anxiety\n",
      "\n",
      "PREDICTION TEXT:\n",
      "answer: A. Because a court case is dismissed after hearing testimony, anguish would be a likely cause.\n",
      "\n",
      "================================================================================\n",
      "CoS-E example 3\n",
      "Correct letter: C\n",
      "Predicted letter: C\n",
      "RIGHT ✓\n",
      "\n",
      "QUESTION:\n",
      "Running errands with screaming kids will likely cause what?\n",
      "\n",
      "CHOICES:\n",
      "  A: efficiency\n",
      "  B: insanity\n",
      "  C: aggravation\n",
      "  D: tiredness\n",
      "  E: stress\n",
      "\n",
      "PREDICTION TEXT:\n",
      "answer: C. Because running errands with screaming kids causes aggravation.\n",
      "\n",
      "================================================================================\n",
      "CoS-E example 4\n",
      "Correct letter: E\n",
      "Predicted letter: E\n",
      "RIGHT ✓\n",
      "\n",
      "QUESTION:\n",
      "WHere do people live?\n",
      "\n",
      "CHOICES:\n",
      "  A: apartment\n",
      "  B: eat cake\n",
      "  C: bus depot\n",
      "  D: football stadium\n",
      "  E: surface of earth\n",
      "\n",
      "PREDICTION TEXT:\n",
      "answer: E. Because an apartment is a place where people live.\n",
      "\n",
      "Saved CSV to: ./flan_t5_base_csqa_lora_v2\\cose_v1_11_val_sample_outputs.csv\n",
      "Saved JSONL to: ./flan_t5_base_csqa_lora_v2\\cose_v1_11_val_sample_outputs.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from peft import PeftModel\n",
    "\n",
    "# ==========================\n",
    "# 0. Device\n",
    "# ==========================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ==========================\n",
    "# 1. Load CSQA-trained FLAN-T5-base + LoRA (checkpoint-1461)\n",
    "# ==========================\n",
    "\n",
    "base_model_name = \"google/flan-t5-base\"\n",
    "checkpoint_dir = \"./flan_t5_base_csqa_lora_v2/checkpoint-1461\"  # adjust if needed\n",
    "\n",
    "print(\"Loading base model and LoRA checkpoint...\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(\n",
    "    base_model_name\n",
    ").to(device)\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    checkpoint_dir,\n",
    ").to(device)\n",
    "\n",
    "model.eval()\n",
    "print(\"Loaded model from\", checkpoint_dir)\n",
    "\n",
    "max_input_length = 384\n",
    "max_target_length = 96\n",
    "\n",
    "# ==========================\n",
    "# 2. Load CoS-E v1.11 from HuggingFace\n",
    "# ==========================\n",
    "\n",
    "print(\"Loading CoS-E v1.11 dataset...\")\n",
    "dataset = load_dataset(\"Salesforce/cos_e\", \"v1.11\")\n",
    "\n",
    "train_raw = dataset[\"train\"]\n",
    "val_raw = dataset[\"validation\"]\n",
    "\n",
    "print(\"Example raw sample:\")\n",
    "print(train_raw[0])\n",
    "\n",
    "# ==========================\n",
    "# 3. Build multiple-choice formatted dataset\n",
    "# ==========================\n",
    "\n",
    "def build_mc(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    choices = example[\"choices\"]\n",
    "    answer = example[\"answer\"]\n",
    "\n",
    "    if not isinstance(choices, list) or len(choices) < 3:\n",
    "        return {\"valid\": False}\n",
    "    if answer not in choices:\n",
    "        return {\"valid\": False}\n",
    "\n",
    "    return {\n",
    "        \"id\": example[\"id\"],\n",
    "        \"question\": example[\"question\"],\n",
    "        \"choices\": choices,\n",
    "        \"answer\": answer,\n",
    "        \"answer_idx\": choices.index(answer),\n",
    "        \"abstractive_explanation\": example[\"abstractive_explanation\"],\n",
    "        \"extractive_explanation\": example[\"extractive_explanation\"],\n",
    "        \"valid\": True,\n",
    "    }\n",
    "\n",
    "print(\"Building MC version...\")\n",
    "train_mc = train_raw.map(build_mc)\n",
    "val_mc = val_raw.map(build_mc)\n",
    "\n",
    "train_mc = train_mc.filter(lambda x: x[\"valid\"])\n",
    "val_mc = val_mc.filter(lambda x: x[\"valid\"])\n",
    "\n",
    "print(\"Example MC sample:\")\n",
    "print(train_mc[0])\n",
    "\n",
    "# ==========================\n",
    "# 4. Helper to extract answer letter from model output\n",
    "# ==========================\n",
    "\n",
    "def extract_answer(pred_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract choice letter (A-F) from model prediction.\n",
    "    Looks for patterns like 'answer: B', 'answer B.', etc.\n",
    "    \"\"\"\n",
    "    text = pred_text.strip().lower()\n",
    "    m = re.search(r\"answer[: ]*\\s*([a-f])\", text)\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "    return None\n",
    "\n",
    "# ==========================\n",
    "# 5. Sample up to 200 examples from CoS-E validation MC\n",
    "# ==========================\n",
    "\n",
    "val_size = len(val_mc)\n",
    "n_eval = min(200, val_size)\n",
    "\n",
    "print(f\"Validation MC size: {val_size}, evaluating on {n_eval} examples\")\n",
    "\n",
    "val_mc_shuffled = val_mc.shuffle(seed=42)\n",
    "subset = val_mc_shuffled.select(range(n_eval))\n",
    "\n",
    "# ==========================\n",
    "# 6. Run evaluation\n",
    "# ==========================\n",
    "\n",
    "letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "correct = 0\n",
    "results: List[Dict[str, Any]] = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ex in subset:\n",
    "        question = ex[\"question\"]\n",
    "        choices = ex[\"choices\"]              # list of strings\n",
    "        answer_idx = ex[\"answer_idx\"]        # correct index\n",
    "        gold_letter = letters[answer_idx]    # \"A\"/\"B\"/...\n",
    "\n",
    "        formatted_choices = \"; \".join(\n",
    "            f\"{letters[i]}: {choices[i]}\" for i in range(len(choices))\n",
    "        )\n",
    "\n",
    "        input_text = (\n",
    "            f\"question: {question}\\n\"\n",
    "            f\"choices: {formatted_choices}\\n\"\n",
    "            f\"explain your answer:\"\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            input_text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=max_input_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        gen_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"].to(device),\n",
    "            max_length=max_target_length,\n",
    "            num_beams=4,\n",
    "        )\n",
    "\n",
    "        pred_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "        pred_letter = extract_answer(pred_text)\n",
    "\n",
    "        is_correct = (pred_letter == gold_letter)\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"id\": ex[\"id\"],\n",
    "                \"question\": question,\n",
    "                \"choices\": choices,\n",
    "                \"correct_letter\": gold_letter,\n",
    "                \"correct_answer_text\": ex[\"answer\"],\n",
    "                \"predicted_letter\": pred_letter,\n",
    "                \"prediction_text\": pred_text,\n",
    "                \"is_correct\": is_correct,\n",
    "            }\n",
    "        )\n",
    "\n",
    "accuracy = correct / n_eval if n_eval > 0 else 0.0\n",
    "print(f\"\\nCoS-E v1.11 validation accuracy on {n_eval} examples: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# ==========================\n",
    "# 7. Show first few examples\n",
    "# ==========================\n",
    "\n",
    "num_show = 5\n",
    "for i, rec in enumerate(results[:num_show]):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"CoS-E example {i}\")\n",
    "    print(f\"Correct letter: {rec['correct_letter']}\")\n",
    "    print(f\"Predicted letter: {rec['predicted_letter']}\")\n",
    "    print(\"RIGHT ✓\" if rec[\"is_correct\"] else \"WRONG ✗\")\n",
    "\n",
    "    print(\"\\nQUESTION:\")\n",
    "    print(rec[\"question\"])\n",
    "\n",
    "    print(\"\\nCHOICES:\")\n",
    "    for idx, text in enumerate(rec[\"choices\"]):\n",
    "        print(f\"  {letters[idx]}: {text}\")\n",
    "\n",
    "    print(\"\\nPREDICTION TEXT:\")\n",
    "    print(rec[\"prediction_text\"])\n",
    "    print()\n",
    "\n",
    "# ==========================\n",
    "# 8. Save results (optional)\n",
    "# ==========================\n",
    "\n",
    "out_dir = \"./flan_t5_base_csqa_lora_v2\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(out_dir, \"cose_v1_11_val_sample_outputs.csv\")\n",
    "jsonl_path = os.path.join(out_dir, \"cose_v1_11_val_sample_outputs.jsonl\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(csv_path, index=False)\n",
    "print(\"Saved CSV to:\", csv_path)\n",
    "\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in results:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Saved JSONL to:\", jsonl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4cfb04d-3c25-4c6c-afa6-9aca9eac27bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 4.57.3\n",
      "peft version: 0.18.0\n",
      "device: cuda\n",
      "Loaded examples: 9741\n",
      "Example raw row: {'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?', 'choices': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid'], 'answer': 'A', 'short_explanation': 'Because \"ignore\" best shows the sanctions disregarded the school\\'s efforts to change.'}\n",
      "Processed examples: 9741\n",
      "Example formatted input:\n",
      " question: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "choices: A: ignore; B: enforce; C: authoritarian; D: yell at; E: avoid\n",
      "explain your answer:\n",
      "Example formatted target:\n",
      " answer: A. Because \"ignore\" best shows the sanctions disregarded the school's efforts to change.\n",
      "total: 9741 train: 7792 val: 1949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bffa91529a4cde96adc2f1fb6c032b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\py\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f6d239852241f387599d7ac6de0a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sizes: 7792 1949\n",
      "trainable params: 4,718,592 || all params: 787,868,672 || trainable%: 0.5989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanch\\AppData\\Local\\Temp\\ipykernel_61640\\3384732169.py:212: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='974' max='974' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [974/974 10:14:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>35.450800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>33.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>27.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>20.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>16.924100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>15.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>13.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>11.258400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>9.525800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>6.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.606800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.184200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.926400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.512700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.438400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.426800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=974, training_loss=12.203589570595744, metrics={'train_runtime': 36907.8475, 'train_samples_per_second': 0.422, 'train_steps_per_second': 0.026, 'total_flos': 2.7107551384436736e+16, 'train_loss': 12.203589570595744, 'epoch': 2.0})\n",
      "Saved LoRA FLAN-T5-large model to ./flan_t5_large_csqa_lora_v1\n",
      "Saved training log to ./flan_t5_large_csqa_lora_v1/training_log_large.csv\n",
      "Saved loss curve figure to ./flan_t5_large_csqa_lora_v1/training_loss_large.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "print(\"transformers version:\", __import__(\"transformers\").__version__)\n",
    "print(\"peft version:\", __import__(\"peft\").__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# =========================\n",
    "# 1. Load data and preprocess\n",
    "# =========================\n",
    "\n",
    "data_path = \"csqa_full_clean_v2.jsonl\"\n",
    "\n",
    "rows = []\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        rows.append(json.loads(line))\n",
    "\n",
    "print(\"Loaded examples:\", len(rows))\n",
    "print(\"Example raw row:\", rows[0])\n",
    "\n",
    "\n",
    "def clean_explanation(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = text.replace(\"```\", \"\").replace(\"`\", \"\")\n",
    "    text = re.sub(\n",
    "        r\"\\bplaintext\\b|\\bpython\\b|\\bjson\\b|\\btext\\b\",\n",
    "        \"\",\n",
    "        text,\n",
    "        flags=re.IGNORECASE,\n",
    "    )\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"^(Because\\s+)+\", \"Because \", text, flags=re.IGNORECASE)\n",
    "    if text and not text.endswith(\".\"):\n",
    "        text += \".\"\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def format_choices(choice_list):\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "    return \"; \".join(\n",
    "        f\"{letters[i]}: {choice_list[i]}\" for i in range(len(choice_list))\n",
    "    )\n",
    "\n",
    "\n",
    "processed = []\n",
    "for ex in rows:\n",
    "    q = ex[\"question\"]\n",
    "    choices = ex[\"choices\"]\n",
    "    ans = ex[\"answer\"]              # \"A\" / \"B\" / ...\n",
    "    expl = clean_explanation(ex.get(\"short_explanation\", \"\"))\n",
    "\n",
    "    input_text = (\n",
    "        f\"question: {q}\\n\"\n",
    "        f\"choices: {format_choices(choices)}\\n\"\n",
    "        f\"explain your answer:\"\n",
    "    )\n",
    "    target_text = f\"answer: {ans}. {expl}\"\n",
    "\n",
    "    processed.append(\n",
    "        {\n",
    "            \"input_text\": input_text,\n",
    "            \"target_text\": target_text,\n",
    "            \"answer\": ans,        # keep answer for later eval\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Processed examples:\", len(processed))\n",
    "print(\"Example formatted input:\\n\", processed[0][\"input_text\"])\n",
    "print(\"Example formatted target:\\n\", processed[0][\"target_text\"])\n",
    "\n",
    "# =========================\n",
    "# 2. Split into train/val (80/20)\n",
    "# =========================\n",
    "\n",
    "dataset = Dataset.from_list(processed)\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "val_dataset = dataset.select(range(train_size, total_size))\n",
    "\n",
    "print(\"total:\", total_size, \"train:\", len(train_dataset), \"val:\", len(val_dataset))\n",
    "\n",
    "# =========================\n",
    "# 3. Tokenizer and tokenization (FLAN-T5-large)\n",
    "# =========================\n",
    "\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_input_length = 384\n",
    "max_target_length = 96\n",
    "\n",
    "\n",
    "def basic_clean(t: str) -> str:\n",
    "    if t is None:\n",
    "        return \"\"\n",
    "    t = str(t)\n",
    "    t = t.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    return t.strip()\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    input_text = basic_clean(example[\"input_text\"])\n",
    "    target_text = basic_clean(example[\"target_text\"])\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        input_text,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            target_text,\n",
    "            max_length=max_target_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "train_tokenized = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=False,\n",
    "    remove_columns=train_dataset.column_names,\n",
    ")\n",
    "val_tokenized = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=False,\n",
    "    remove_columns=val_dataset.column_names,\n",
    ")\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_tokenized.set_format(type=\"torch\", columns=cols)\n",
    "val_tokenized.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "print(\"Tokenized sizes:\", len(train_tokenized), len(val_tokenized))\n",
    "\n",
    "# =========================\n",
    "# 4. Load FLAN-T5-large + LoRA\n",
    "# =========================\n",
    "\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    task_type=\"SEQ_2_SEQ_LM\",   # string style, same as your old code\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# =========================\n",
    "# 5. TrainingArguments (smaller LR, fewer epochs) + Trainer\n",
    "# =========================\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./flan_t5_large_csqa_lora_v1\",\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    num_train_epochs=2,                 # shorter than 3\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "\n",
    "    learning_rate=3e-5,                 # smaller LR for large model\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    fp16=False,                         # full precision for stability\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "print(train_result)\n",
    "\n",
    "# =========================\n",
    "# 6. Save model, tokenizer, and training logs\n",
    "# =========================\n",
    "\n",
    "save_dir = \"./flan_t5_large_csqa_lora_v1\"\n",
    "\n",
    "trainer.model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(\"Saved LoRA FLAN-T5-large model to\", save_dir)\n",
    "\n",
    "# ---- save raw training log ----\n",
    "log_history = trainer.state.log_history\n",
    "log_df = pd.DataFrame(log_history)\n",
    "log_csv_path = f\"{save_dir}/training_log_large.csv\"\n",
    "log_df.to_csv(log_csv_path, index=False)\n",
    "print(\"Saved training log to\", log_csv_path)\n",
    "\n",
    "# ---- plot training loss curve ----\n",
    "loss_df = log_df[log_df[\"loss\"].notna()] if \"loss\" in log_df.columns else pd.DataFrame()\n",
    "\n",
    "if not loss_df.empty:\n",
    "    plt.figure()\n",
    "    plt.plot(loss_df[\"step\"], loss_df[\"loss\"])\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"Training loss - FLAN-T5-large LoRA\")\n",
    "    plt.grid(True)\n",
    "    loss_fig_path = f\"{save_dir}/training_loss_large.png\"\n",
    "    plt.savefig(loss_fig_path, bbox_inches=\"tight\")\n",
    "    print(\"Saved loss curve figure to\", loss_fig_path)\n",
    "else:\n",
    "    print(\"No loss data found in log history.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4679228f-3056-4c3f-add7-efae37d18690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 validation examples (sampled from 1949)\n",
      "Validation accuracy on 200 examples: 0.3750 (37.50%)\n",
      "================================================================================\n",
      "Validation example 0\n",
      "Correct answer: E\n",
      "Predicted: None\n",
      "WRONG ✗\n",
      "\n",
      "INPUT:\n",
      "question: Danny needed a new mouse, his was jumping around whenever he moved it. Where might his mouse be?\n",
      "choices: A: abandoned houses; B: corn field; C: cupboard; D: cabinet; E: desktop\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: E. Because a desktop allows for a mouse's typical use and movement, making E the correct answer.\n",
      "\n",
      "PREDICTION:\n",
      "When a mouse jumps around, it needs a new one. The answer is E.\n",
      "\n",
      "================================================================================\n",
      "Validation example 1\n",
      "Correct answer: A\n",
      "Predicted: A\n",
      "RIGHT ✓\n",
      "\n",
      "INPUT:\n",
      "question: Who can have the most influence on washington from a given county?\n",
      "choices: A: representative; B: cleverest; C: bitterest; D: alter; E: sweet\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: A. Because representatives have formal channels to influence federal legislation, making A the correct choice.\n",
      "\n",
      "PREDICTION:\n",
      "Having the most influence on Washington from a given county is called a representative. Representatives can have the most influence on Washington from a given county. The answer: A.\n",
      "\n",
      "================================================================================\n",
      "Validation example 2\n",
      "Correct answer: A\n",
      "Predicted: A\n",
      "RIGHT ✓\n",
      "\n",
      "INPUT:\n",
      "question: The brothers were punching angrily, why would they do that?\n",
      "choices: A: cause pain; B: to defend themselves.; C: broken bones; D: bruise; E: pain for\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: A. Because the brothers punched angrily to cause pain reflecting their aggressive state.\n",
      "\n",
      "PREDICTION:\n",
      "When people are angry, they tend to punch. When people punch angrily, they tend to cause pain. The answer: A.\n",
      "\n",
      "================================================================================\n",
      "Validation example 3\n",
      "Correct answer: E\n",
      "Predicted: None\n",
      "WRONG ✗\n",
      "\n",
      "INPUT:\n",
      "question: What does the D in DRC stand for?\n",
      "choices: A: dictatorship; B: democracy; C: democracy; D: state; E: democratic\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: E. Because \"Democratic\" in DRC indicates the government's republican and people-oriented ideals.\n",
      "\n",
      "PREDICTION:\n",
      "drc stands for democratic republic of congo.\n",
      "\n",
      "================================================================================\n",
      "Validation example 4\n",
      "Correct answer: B\n",
      "Predicted: None\n",
      "WRONG ✗\n",
      "\n",
      "INPUT:\n",
      "question: Becoming inebriated leads to what state?\n",
      "choices: A: regret; B: drunkenness; C: high energy; D: paralysis; E: arrest\n",
      "explain your answer:\n",
      "\n",
      "TARGET:\n",
      "answer: B. Because \"drunkenness\" precisely describes the state of inebriation caused by alcohol consumption.\n",
      "\n",
      "PREDICTION:\n",
      "Inebriation is the state of being intoxicated. Drunkenness is the state of being intoxicated. The answer is B.\n",
      "\n",
      "Saved CSV to: ./flan_t5_large_csqa_lora_v1\\validation_sample_outputs_large.csv\n",
      "Saved JSONL to: ./flan_t5_large_csqa_lora_v1\\validation_sample_outputs_large.jsonl\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure this is your FLAN-T5-large LoRA model\n",
    "model.eval()  # eval mode\n",
    "\n",
    "\n",
    "def extract_answer(pred_text: str):\n",
    "    \"\"\"\n",
    "    Extract choice letter (A-F) from model prediction.\n",
    "    Looks for patterns like 'answer: B', 'answer B.', etc.\n",
    "    \"\"\"\n",
    "    text = pred_text.strip().lower()\n",
    "    m = re.search(r\"answer[: ]*\\s*([a-f])\", text)\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Sample up to 200 examples from validation set\n",
    "# =========================\n",
    "\n",
    "val_size = len(val_dataset)\n",
    "n_eval = min(200, val_size)\n",
    "\n",
    "indices = list(range(val_size))\n",
    "random.seed(42)  # reproducibility\n",
    "sample_indices = random.sample(indices, n_eval)\n",
    "\n",
    "# local indices in val_dataset -> global indices in rows\n",
    "# val_dataset is dataset[train_size:] part\n",
    "global_indices = [train_size + i for i in sample_indices]\n",
    "\n",
    "subset = val_dataset.select(sample_indices)\n",
    "subset_list = list(subset)\n",
    "\n",
    "print(f\"Using {n_eval} validation examples (sampled from {val_size})\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Run model, compute accuracy, collect predictions\n",
    "# =========================\n",
    "\n",
    "results = []  # list of dicts\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ex, g_idx in zip(subset_list, global_indices):\n",
    "        # gold answer comes from original rows\n",
    "        gold_answer = rows[g_idx][\"answer\"]  # \"A\", \"B\", ...\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            ex[\"input_text\"],\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=max_input_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        gen_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"].to(device),\n",
    "            max_length=max_target_length,\n",
    "            num_beams=4,\n",
    "        )\n",
    "\n",
    "        pred_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "        pred_ans = extract_answer(pred_text)\n",
    "\n",
    "        is_correct = (pred_ans == gold_answer)\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"input_text\": ex[\"input_text\"],\n",
    "                \"target_text\": ex[\"target_text\"],\n",
    "                \"correct_answer\": gold_answer,\n",
    "                \"predicted_answer\": pred_ans,\n",
    "                \"prediction_text\": pred_text,\n",
    "                \"is_correct\": is_correct,\n",
    "            }\n",
    "        )\n",
    "\n",
    "accuracy = correct / n_eval if n_eval > 0 else 0.0\n",
    "print(f\"Validation accuracy on {n_eval} examples: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Show first few examples with predictions\n",
    "# =========================\n",
    "\n",
    "num_show = 5\n",
    "\n",
    "for i, rec in enumerate(results[:num_show]):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Validation example {i}\")\n",
    "    print(f\"Correct answer: {rec['correct_answer']}\")\n",
    "    print(f\"Predicted: {rec['predicted_answer']}\")\n",
    "    print(\"RIGHT ✓\" if rec[\"is_correct\"] else \"WRONG ✗\")\n",
    "\n",
    "    print(\"\\nINPUT:\")\n",
    "    print(rec[\"input_text\"])\n",
    "\n",
    "    print(\"\\nTARGET:\")\n",
    "    print(rec[\"target_text\"])\n",
    "\n",
    "    print(\"\\nPREDICTION:\")\n",
    "    print(rec[\"prediction_text\"])\n",
    "    print()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Save these 200 (or fewer) results to CSV and JSONL\n",
    "# =========================\n",
    "\n",
    "try:\n",
    "    out_dir = trainer.args.output_dir\n",
    "except NameError:\n",
    "    # change this to your FLAN-T5-large output dir if different\n",
    "    out_dir = \"./flan_t5_large_csqa_lora_v1\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(out_dir, \"validation_sample_outputs_large.csv\")\n",
    "jsonl_path = os.path.join(out_dir, \"validation_sample_outputs_large.jsonl\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(csv_path, index=False)\n",
    "print(\"Saved CSV to:\", csv_path)\n",
    "\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in results:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Saved JSONL to:\", jsonl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "962dff7b-99b7-4cc7-b0d3-10b4c2b557c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 200 validation examples (sampled from 1949)\n",
      "Validation accuracy (lenient v2) on 200 examples: 0.8150 (81.50%)\n",
      "================================================================================\n",
      "Validation example 0\n",
      "Correct answer: E (desktop)\n",
      "Predicted letter: E\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Danny needed a new mouse, his was jumping around whenever he moved it. Where might his mouse be?\n",
      "choices: A: abandoned houses; B: corn field; C: cupboard; D: cabinet; E: desktop\n",
      "explain your answer:\n",
      "\n",
      "PREDICTION:\n",
      "When a mouse jumps around, it needs a new one. The answer is E.\n",
      "\n",
      "================================================================================\n",
      "Validation example 1\n",
      "Correct answer: A (representative)\n",
      "Predicted letter: A\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Who can have the most influence on washington from a given county?\n",
      "choices: A: representative; B: cleverest; C: bitterest; D: alter; E: sweet\n",
      "explain your answer:\n",
      "\n",
      "PREDICTION:\n",
      "Having the most influence on Washington from a given county is called a representative. Representatives can have the most influence on Washington from a given county. The answer: A.\n",
      "\n",
      "================================================================================\n",
      "Validation example 2\n",
      "Correct answer: A (cause pain)\n",
      "Predicted letter: A\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: The brothers were punching angrily, why would they do that?\n",
      "choices: A: cause pain; B: to defend themselves.; C: broken bones; D: bruise; E: pain for\n",
      "explain your answer:\n",
      "\n",
      "PREDICTION:\n",
      "When people are angry, they tend to punch. When people punch angrily, they tend to cause pain. The answer: A.\n",
      "\n",
      "================================================================================\n",
      "Validation example 3\n",
      "Correct answer: E (democratic)\n",
      "Predicted letter: E\n",
      "RIGHT ✓ (via gold text match)\n",
      "\n",
      "INPUT:\n",
      "question: What does the D in DRC stand for?\n",
      "choices: A: dictatorship; B: democracy; C: democracy; D: state; E: democratic\n",
      "explain your answer:\n",
      "\n",
      "PREDICTION:\n",
      "drc stands for democratic republic of congo.\n",
      "\n",
      "================================================================================\n",
      "Validation example 4\n",
      "Correct answer: B (drunkenness)\n",
      "Predicted letter: B\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Becoming inebriated leads to what state?\n",
      "choices: A: regret; B: drunkenness; C: high energy; D: paralysis; E: arrest\n",
      "explain your answer:\n",
      "\n",
      "PREDICTION:\n",
      "Inebriation is the state of being intoxicated. Drunkenness is the state of being intoxicated. The answer is B.\n",
      "\n",
      "Saved CSV to: ./flan_t5_large_csqa_lora_v1\\validation_sample_outputs_large_lenient_v2.csv\n",
      "Saved JSONL to: ./flan_t5_large_csqa_lora_v1\\validation_sample_outputs_large_lenient_v2.jsonl\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure this is your FLAN-T5-large LoRA model\n",
    "model.eval()  # eval mode\n",
    "\n",
    "\n",
    "def extract_answer_letter(pred_text: str):\n",
    "    \"\"\"\n",
    "    Try to extract choice letter (A-F) from model prediction.\n",
    "    Handles patterns like:\n",
    "      - answer: B\n",
    "      - answer B\n",
    "      - answer is B\n",
    "      - the answer is B\n",
    "      - the answer: B\n",
    "    \"\"\"\n",
    "    text = pred_text.strip().lower()\n",
    "\n",
    "    # main pattern: optional \"the\", then \"answer\", then (is | : | space), then letter\n",
    "    m = re.search(\n",
    "        r\"(?:the\\s+)?answer(?:\\s+is|[: ]+)\\s*([a-f])\",\n",
    "        text,\n",
    "    )\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "\n",
    "    # fallback: old very simple pattern, just in case\n",
    "    m2 = re.search(r\"answer[: ]*\\s*([a-f])\", text)\n",
    "    if m2:\n",
    "        return m2.group(1).upper()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Sample up to 200 examples from validation set\n",
    "# =========================\n",
    "\n",
    "val_size = len(val_dataset)\n",
    "n_eval = min(200, val_size)\n",
    "\n",
    "indices = list(range(val_size))\n",
    "random.seed(42)  # reproducibility\n",
    "sample_indices = random.sample(indices, n_eval)\n",
    "\n",
    "# local indices in val_dataset -> global indices in rows\n",
    "# val_dataset is dataset[train_size:] part\n",
    "global_indices = [train_size + i for i in sample_indices]\n",
    "\n",
    "subset = val_dataset.select(sample_indices)\n",
    "subset_list = list(subset)\n",
    "\n",
    "print(f\"Using {n_eval} validation examples (sampled from {val_size})\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Run model, compute accuracy (lenient), collect predictions\n",
    "# =========================\n",
    "\n",
    "results = []  # list of dicts\n",
    "correct = 0\n",
    "letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ex, g_idx in zip(subset_list, global_indices):\n",
    "        raw = rows[g_idx]\n",
    "        gold_answer = raw[\"answer\"]         # \"A\", \"B\", ...\n",
    "        choices = raw[\"choices\"]            # list of choice texts\n",
    "\n",
    "        # gold choice text (what the option actually says)\n",
    "        gold_idx = letters.index(gold_answer)\n",
    "        gold_text = str(choices[gold_idx]).strip().lower()\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            ex[\"input_text\"],\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=max_input_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        gen_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"].to(device),\n",
    "            max_length=max_target_length,\n",
    "            num_beams=4,\n",
    "        )\n",
    "\n",
    "        pred_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "        pred_text_lower = pred_text.lower()\n",
    "\n",
    "        # 1) try to extract letter explicitly (\"the answer is B\", \"answer: C\", etc.)\n",
    "        letter_from_text = extract_answer_letter(pred_text)\n",
    "\n",
    "        # 2) fallback: check if model clearly mentions the gold option text\n",
    "        contains_gold = gold_text != \"\" and gold_text in pred_text_lower\n",
    "\n",
    "        # final decision\n",
    "        is_correct = False\n",
    "        predicted_answer = None\n",
    "        used_gold_text_match = False\n",
    "\n",
    "        if letter_from_text is not None:\n",
    "            predicted_answer = letter_from_text\n",
    "            if letter_from_text == gold_answer:\n",
    "                is_correct = True\n",
    "        elif contains_gold:\n",
    "            predicted_answer = gold_answer\n",
    "            is_correct = True\n",
    "            used_gold_text_match = True\n",
    "\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"input_text\": ex[\"input_text\"],\n",
    "                \"target_text\": ex[\"target_text\"],\n",
    "                \"choices\": choices,\n",
    "                \"correct_answer\": gold_answer,\n",
    "                \"correct_choice_text\": choices[gold_idx],\n",
    "                \"predicted_answer\": predicted_answer,\n",
    "                \"prediction_text\": pred_text,\n",
    "                \"used_gold_text_match\": used_gold_text_match,\n",
    "                \"is_correct\": is_correct,\n",
    "            }\n",
    "        )\n",
    "\n",
    "accuracy = correct / n_eval if n_eval > 0 else 0.0\n",
    "print(f\"Validation accuracy (lenient v2) on {n_eval} examples: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Show first few examples with predictions\n",
    "# =========================\n",
    "\n",
    "num_show = 5\n",
    "\n",
    "for i, rec in enumerate(results[:num_show]):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Validation example {i}\")\n",
    "    print(f\"Correct answer: {rec['correct_answer']} ({rec['correct_choice_text']})\")\n",
    "    print(f\"Predicted letter: {rec['predicted_answer']}\")\n",
    "    flag = \"\"\n",
    "    if rec[\"used_gold_text_match\"]:\n",
    "        flag = \"(via gold text match)\"\n",
    "    print(\"RIGHT ✓\" if rec[\"is_correct\"] else \"WRONG ✗\", flag)\n",
    "\n",
    "    print(\"\\nINPUT:\")\n",
    "    print(rec[\"input_text\"])\n",
    "\n",
    "    print(\"\\nPREDICTION:\")\n",
    "    print(rec[\"prediction_text\"])\n",
    "    print()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Save these 200 (or fewer) results to CSV and JSONL\n",
    "# =========================\n",
    "\n",
    "try:\n",
    "    out_dir = trainer.args.output_dir\n",
    "except NameError:\n",
    "    # your FLAN-T5-large output dir\n",
    "    out_dir = \"./flan_t5_large_csqa_lora_v1\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# new filenames to distinguish from previous versions\n",
    "csv_path = os.path.join(out_dir, \"validation_sample_outputs_large_lenient_v2.csv\")\n",
    "jsonl_path = os.path.join(out_dir, \"validation_sample_outputs_large_lenient_v2.jsonl\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(csv_path, index=False)\n",
    "print(\"Saved CSV to:\", csv_path)\n",
    "\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in results:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Saved JSONL to:\", jsonl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "762a309b-7358-4dc1-a49e-0b26e7d392bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 163  Wrong: 37\n",
      "\n",
      "===================================  CORRECT EXAMPLES  ===================================\n",
      "================================================================================\n",
      "Correct example 0\n",
      "Correct answer: E (desktop)\n",
      "Predicted: E\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Danny needed a new mouse, his was jumping around whenever he moved it. Where might his mouse be?\n",
      "choices: A: abandoned houses; B: corn field; C: cupboard; D: cabinet; E: desktop\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: abandoned houses\n",
      "B: corn field\n",
      "C: cupboard\n",
      "D: cabinet\n",
      "E: desktop\n",
      "\n",
      "PREDICTION:\n",
      "When a mouse jumps around, it needs a new one. The answer is E.\n",
      "\n",
      "================================================================================\n",
      "Correct example 1\n",
      "Correct answer: A (representative)\n",
      "Predicted: A\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Who can have the most influence on washington from a given county?\n",
      "choices: A: representative; B: cleverest; C: bitterest; D: alter; E: sweet\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: representative\n",
      "B: cleverest\n",
      "C: bitterest\n",
      "D: alter\n",
      "E: sweet\n",
      "\n",
      "PREDICTION:\n",
      "Having the most influence on Washington from a given county is called a representative. Representatives can have the most influence on Washington from a given county. The answer: A.\n",
      "\n",
      "================================================================================\n",
      "Correct example 2\n",
      "Correct answer: A (cause pain)\n",
      "Predicted: A\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: The brothers were punching angrily, why would they do that?\n",
      "choices: A: cause pain; B: to defend themselves.; C: broken bones; D: bruise; E: pain for\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: cause pain\n",
      "B: to defend themselves.\n",
      "C: broken bones\n",
      "D: bruise\n",
      "E: pain for\n",
      "\n",
      "PREDICTION:\n",
      "When people are angry, they tend to punch. When people punch angrily, they tend to cause pain. The answer: A.\n",
      "\n",
      "================================================================================\n",
      "Correct example 3\n",
      "Correct answer: E (democratic)\n",
      "Predicted: E\n",
      "RIGHT ✓ (via gold text match)\n",
      "\n",
      "INPUT:\n",
      "question: What does the D in DRC stand for?\n",
      "choices: A: dictatorship; B: democracy; C: democracy; D: state; E: democratic\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: dictatorship\n",
      "B: democracy\n",
      "C: democracy\n",
      "D: state\n",
      "E: democratic\n",
      "\n",
      "PREDICTION:\n",
      "drc stands for democratic republic of congo.\n",
      "\n",
      "================================================================================\n",
      "Correct example 4\n",
      "Correct answer: B (drunkenness)\n",
      "Predicted: B\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Becoming inebriated leads to what state?\n",
      "choices: A: regret; B: drunkenness; C: high energy; D: paralysis; E: arrest\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: regret\n",
      "B: drunkenness\n",
      "C: high energy\n",
      "D: paralysis\n",
      "E: arrest\n",
      "\n",
      "PREDICTION:\n",
      "Inebriation is the state of being intoxicated. Drunkenness is the state of being intoxicated. The answer is B.\n",
      "\n",
      "================================================================================\n",
      "Correct example 5\n",
      "Correct answer: A (painful memories)\n",
      "Predicted: A\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: The archaeologist was seeing artifacts that he had lost long ago while reading a textbook, what did this bring up?\n",
      "choices: A: painful memories; B: poor planning; C: thinking; D: learning; E: angry\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: painful memories\n",
      "B: poor planning\n",
      "C: thinking\n",
      "D: learning\n",
      "E: angry\n",
      "\n",
      "PREDICTION:\n",
      "The archaeologist was seeing artifacts that he had lost long ago while reading a textbook. The answer: A.\n",
      "\n",
      "================================================================================\n",
      "Correct example 6\n",
      "Correct answer: B (buying)\n",
      "Predicted: B\n",
      "RIGHT ✓ (via gold text match)\n",
      "\n",
      "INPUT:\n",
      "question: He enjoyed reading newspaper, he consider what a subscription?\n",
      "choices: A: gifting; B: buying; C: money; D: literacy; E: knowing how to read\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: gifting\n",
      "B: buying\n",
      "C: money\n",
      "D: literacy\n",
      "E: knowing how to read\n",
      "\n",
      "PREDICTION:\n",
      "Buying a newspaper is a type of subscription. He enjoyed reading newspaper so he consider buying newspaper as a subscription.\n",
      "\n",
      "================================================================================\n",
      "Correct example 7\n",
      "Correct answer: D (foreign country)\n",
      "Predicted: D\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Outside of a zoo where are you likely to find a marmoset?\n",
      "choices: A: another place; B: france; C: venezuela; D: foreign country; E: woods\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: another place\n",
      "B: france\n",
      "C: venezuela\n",
      "D: foreign country\n",
      "E: woods\n",
      "\n",
      "PREDICTION:\n",
      "The Marmoset is endemic to the Democratic Republic of the Congo. Outside of a zoo, you are likely to find a Marmoset in a foreign country. The answer: D.\n",
      "\n",
      "================================================================================\n",
      "Correct example 8\n",
      "Correct answer: A (convention)\n",
      "Predicted: A\n",
      "RIGHT ✓ (via gold text match)\n",
      "\n",
      "INPUT:\n",
      "question: What sort of gathering might business people attend to get updates about their industry?\n",
      "choices: A: convention; B: school; C: opera; D: wedding; E: bus stop\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: convention\n",
      "B: school\n",
      "C: opera\n",
      "D: wedding\n",
      "E: bus stop\n",
      "\n",
      "PREDICTION:\n",
      "Business people attend convention to get updates about their industry to get updates about their industry.\n",
      "\n",
      "================================================================================\n",
      "Correct example 9\n",
      "Correct answer: C (horseradish)\n",
      "Predicted: C\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: They made a mess eating on the sofa bed, they dripped a tangy what sauce all over it?\n",
      "choices: A: basement; B: guest room; C: horseradish; D: bathroom; E: living room\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: basement\n",
      "B: guest room\n",
      "C: horseradish\n",
      "D: bathroom\n",
      "E: living room\n",
      "\n",
      "PREDICTION:\n",
      "Horseradish is a tangy sauce that can be dripped all over a sofa bed. The answer is C.\n",
      "\n",
      "================================================================================\n",
      "Correct example 10\n",
      "Correct answer: B (panic)\n",
      "Predicted: B\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Danny was meeting his friend James, but James didn't show up. James was always punctual. As time wore on and it became clear that his friend wasn't coming, Danny began to do what?\n",
      "choices: A: cheer; B: panic; C: anger; D: relaxation; E: joy\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: cheer\n",
      "B: panic\n",
      "C: anger\n",
      "D: relaxation\n",
      "E: joy\n",
      "\n",
      "PREDICTION:\n",
      "When someone isn't punctual, they tend to show up late. When someone isn't punctual, they tend to show up late. When someone isn't punctual, they tend to show up late. The answer: B.\n",
      "\n",
      "================================================================================\n",
      "Correct example 11\n",
      "Correct answer: D (office)\n",
      "Predicted: D\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Where would you see someone typing on a keyboard?\n",
      "choices: A: landfill; B: finger; C: with camera; D: office; E: music store\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: landfill\n",
      "B: finger\n",
      "C: with camera\n",
      "D: office\n",
      "E: music store\n",
      "\n",
      "PREDICTION:\n",
      "Office is a room or set of rooms or a building where people work, usually sitting at desks. The answer: D.\n",
      "\n",
      "================================================================================\n",
      "Correct example 12\n",
      "Correct answer: D (conference)\n",
      "Predicted: D\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: What do I attend annually to check out the offered programs?\n",
      "choices: A: think tank; B: group functions; C: theater; D: conference; E: television\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: think tank\n",
      "B: group functions\n",
      "C: theater\n",
      "D: conference\n",
      "E: television\n",
      "\n",
      "PREDICTION:\n",
      "A conference is a gathering of people from different parts of the world to discuss, present, and debate a particular topic or issue. The answer: D.\n",
      "\n",
      "================================================================================\n",
      "Correct example 13\n",
      "Correct answer: C (two ears)\n",
      "Predicted: C\n",
      "RIGHT ✓ (via gold text match)\n",
      "\n",
      "INPUT:\n",
      "question: The dog liked to be pet, especially on his floppy what?\n",
      "choices: A: teeth; B: four legs; C: two ears; D: the gas station ran out of gas today.; E: paws\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: teeth\n",
      "B: four legs\n",
      "C: two ears\n",
      "D: the gas station ran out of gas today.\n",
      "E: paws\n",
      "\n",
      "PREDICTION:\n",
      "The dog liked to be pet, especially on his floppy two ears.\n",
      "\n",
      "================================================================================\n",
      "Correct example 14\n",
      "Correct answer: E (dishwasher)\n",
      "Predicted: E\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: The plate was dirty, where did the woman put it?\n",
      "choices: A: garbage; B: kitchen cupboard; C: table; D: flea market; E: dishwasher\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: garbage\n",
      "B: kitchen cupboard\n",
      "C: table\n",
      "D: flea market\n",
      "E: dishwasher\n",
      "\n",
      "PREDICTION:\n",
      "Dishwasher is a device for washing dirty dishes. Dishwasher is a device for washing dirty dishes. The answer: E.\n",
      "\n",
      "================================================================================\n",
      "Correct example 15\n",
      "Correct answer: B (become deaf)\n",
      "Predicted: B\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: John refused to listen to his mother about his music volume. Because of that, he gradually did what?\n",
      "choices: A: might learn; B: become deaf; C: speaking; D: train; E: talking\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: might learn\n",
      "B: become deaf\n",
      "C: speaking\n",
      "D: train\n",
      "E: talking\n",
      "\n",
      "PREDICTION:\n",
      "When one refuses to listen to their mother about their music volume, they gradually become deaf. The answer is B.\n",
      "\n",
      "================================================================================\n",
      "Correct example 16\n",
      "Correct answer: E (alcatraz)\n",
      "Predicted: E\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: Many prison movies take place at what famous prison?\n",
      "choices: A: forest; B: city; C: countryside; D: america; E: alcatraz\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: forest\n",
      "B: city\n",
      "C: countryside\n",
      "D: america\n",
      "E: alcatraz\n",
      "\n",
      "PREDICTION:\n",
      "Alcatraz is a famous prison. Many prison movies take place at Alcatraz. The answer is E.\n",
      "\n",
      "================================================================================\n",
      "Correct example 17\n",
      "Correct answer: C (experience pain)\n",
      "Predicted: C\n",
      "RIGHT ✓ \n",
      "\n",
      "INPUT:\n",
      "question: What's one characteristic that separates a person from a stuffed dummy?\n",
      "choices: A: absorb moisture; B: cross street; C: experience pain; D: deceive himself; E: dead\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: absorb moisture\n",
      "B: cross street\n",
      "C: experience pain\n",
      "D: deceive himself\n",
      "E: dead\n",
      "\n",
      "PREDICTION:\n",
      "A stuffed dummy is not alive. Experience pain is a characteristic that separates a person from a stuffed dummy. The answer: C.\n",
      "\n",
      "================================================================================\n",
      "Correct example 18\n",
      "Correct answer: C (go somewhere)\n",
      "Predicted: C\n",
      "RIGHT ✓ (via gold text match)\n",
      "\n",
      "INPUT:\n",
      "question: If you're bored sitting at a friends home what should you do?\n",
      "choices: A: watch tv; B: socialize; C: go somewhere; D: jump rope; E: clean room\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: watch tv\n",
      "B: socialize\n",
      "C: go somewhere\n",
      "D: jump rope\n",
      "E: clean room\n",
      "\n",
      "PREDICTION:\n",
      "If you're bored sitting at a friend's home, you should go somewhere.\n",
      "\n",
      "================================================================================\n",
      "Correct example 19\n",
      "Correct answer: E (mortal)\n",
      "Predicted: E\n",
      "RIGHT ✓ (via gold text match)\n",
      "\n",
      "INPUT:\n",
      "question: People that follow god are usually what?\n",
      "choices: A: devil; B: better; C: satan; D: dog; E: mortal\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: devil\n",
      "B: better\n",
      "C: satan\n",
      "D: dog\n",
      "E: mortal\n",
      "\n",
      "PREDICTION:\n",
      "People that follow god are usually mortal.\n",
      "\n",
      "\n",
      "===================================  WRONG EXAMPLES  ===================================\n",
      "================================================================================\n",
      "Wrong example 0\n",
      "Correct answer: A (in play)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: If you about to go on stage and are dressed in costume you are likely about to be what?\n",
      "choices: A: in play; B: going to bed; C: have talent; D: teach; E: climb stairs\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: in play\n",
      "B: going to bed\n",
      "C: have talent\n",
      "D: teach\n",
      "E: climb stairs\n",
      "\n",
      "PREDICTION:\n",
      "When you are about to go on stage and are dressed in costume, you are likely about to be in a play.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 1\n",
      "Correct answer: B (worship idols)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: If people are bowing before a statue, what are they likely doing?\n",
      "choices: A: believe in god; B: worship idols; C: knees; D: hope for peace; E: form opinions\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: believe in god\n",
      "B: worship idols\n",
      "C: knees\n",
      "D: hope for peace\n",
      "E: form opinions\n",
      "\n",
      "PREDICTION:\n",
      "When people bow before a statue, they are likely to worship the statue.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 2\n",
      "Correct answer: A (feel pleasure)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: If a person is on vacation what are they likely to achieve?\n",
      "choices: A: feel pleasure; B: look attractive; C: interesting experiences; D: compliments; E: relaxation\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: feel pleasure\n",
      "B: look attractive\n",
      "C: interesting experiences\n",
      "D: compliments\n",
      "E: relaxation\n",
      "\n",
      "PREDICTION:\n",
      "When a person is on a vacation, they are likely to achieve relaxation.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 3\n",
      "Correct answer: D (bake bread)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: I want to make something that I put peanut butter and jelly on; what do I cook?\n",
      "choices: A: open can; B: brown meat; C: add egg; D: bake bread; E: smoke salmon\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: open can\n",
      "B: brown meat\n",
      "C: add egg\n",
      "D: bake bread\n",
      "E: smoke salmon\n",
      "\n",
      "PREDICTION:\n",
      "Putting peanut butter and jelly on bread is a common way to make a sandwich. Baked bread is the most common type of bread to put peanut butter and jelly on.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 4\n",
      "Correct answer: D (get down)\n",
      "Predicted: E\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: When she did occasionally arise to go to the club, what was she looking to do, euphemistically speaking?\n",
      "choices: A: lay down; B: sitting down; C: go down; D: get down; E: sit down\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: lay down\n",
      "B: sitting down\n",
      "C: go down\n",
      "D: get down\n",
      "E: sit down\n",
      "\n",
      "PREDICTION:\n",
      "When she did occasionally arise to go to the club, she was looking to get down. The answer is E.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 5\n",
      "Correct answer: B (learning)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: Spending time seeing artifacts listening to museum lectures will lead to what?\n",
      "choices: A: thinking; B: learning; C: angry; D: archeology; E: pleasure\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: thinking\n",
      "B: learning\n",
      "C: angry\n",
      "D: archeology\n",
      "E: pleasure\n",
      "\n",
      "PREDICTION:\n",
      "Seeing artifacts and listening to museum lectures gives pleasure.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 6\n",
      "Correct answer: B (accomplish)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: If you're telling many people about tasks you perform you have what?\n",
      "choices: A: bragging; B: accomplish; C: annoyance; D: religion; E: learn about\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: bragging\n",
      "B: accomplish\n",
      "C: annoyance\n",
      "D: religion\n",
      "E: learn about\n",
      "\n",
      "PREDICTION:\n",
      "When you are telling many people about tasks you perform, you are annoyance.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 7\n",
      "Correct answer: C (books)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: What would you need a light source to use?\n",
      "choices: A: dard; B: sky; C: books; D: candle; E: house\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: dard\n",
      "B: sky\n",
      "C: books\n",
      "D: candle\n",
      "E: house\n",
      "\n",
      "PREDICTION:\n",
      "When you are reading a book, you would need a light source to read the book.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 8\n",
      "Correct answer: D (satisfaction)\n",
      "Predicted: E\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: Joe wants to have a relationship with someone. He thinks that loving another will bring him what?\n",
      "choices: A: wonderful; B: enjoyment; C: jealousy; D: satisfaction; E: happiness\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: wonderful\n",
      "B: enjoyment\n",
      "C: jealousy\n",
      "D: satisfaction\n",
      "E: happiness\n",
      "\n",
      "PREDICTION:\n",
      "Having a relationship with someone will bring happiness. Happiness is the result of loving another. The answer is E.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 9\n",
      "Correct answer: C (expected)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: A person who found something odd, may have found it odd because it wasn't what?\n",
      "choices: A: even; B: common; C: expected; D: happening; E: habitual\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: even\n",
      "B: common\n",
      "C: expected\n",
      "D: happening\n",
      "E: habitual\n",
      "\n",
      "PREDICTION:\n",
      "When something isn't habitual, it is odd.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 10\n",
      "Correct answer: B (get arrested)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: A person who has been killing people should have what done by the police?\n",
      "choices: A: terrible; B: get arrested; C: commended; D: die; E: going to jail\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: terrible\n",
      "B: get arrested\n",
      "C: commended\n",
      "D: die\n",
      "E: going to jail\n",
      "\n",
      "PREDICTION:\n",
      "When a person has been killing people, he should be arrested by the police.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 11\n",
      "Correct answer: E (express information)\n",
      "Predicted: A\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: The concierge said to ask him any question that you needed answered, he said he can get you what?\n",
      "choices: A: give clue; B: analyse; C: think; D: decipher; E: express information\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: give clue\n",
      "B: analyse\n",
      "C: think\n",
      "D: decipher\n",
      "E: express information\n",
      "\n",
      "PREDICTION:\n",
      "Concierge is a person who can answer any question. The answer: E.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 12\n",
      "Correct answer: A (four legs)\n",
      "Predicted: D\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: What do cats have in common with most mammals?\n",
      "choices: A: four legs; B: whiskers; C: sharp teeth; D: sharp claws; E: glowing eyes\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: four legs\n",
      "B: whiskers\n",
      "C: sharp teeth\n",
      "D: sharp claws\n",
      "E: glowing eyes\n",
      "\n",
      "PREDICTION:\n",
      "Dogs and cats are both mammals. Dogs have sharp teeth and cats have sharp claws. The final answer: D.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 13\n",
      "Correct answer: A (sing)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: What do children often do to express happiness?\n",
      "choices: A: sing; B: play games; C: start fighting; D: fiddle; E: spread\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: sing\n",
      "B: play games\n",
      "C: start fighting\n",
      "D: fiddle\n",
      "E: spread\n",
      "\n",
      "PREDICTION:\n",
      "Laughter is a sign of happiness. Children often laugh to express happiness.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 14\n",
      "Correct answer: E (large city)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: Where is likely to have a popular delicatessen?\n",
      "choices: A: city center; B: mall; C: shop; D: michigan; E: large city\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: city center\n",
      "B: mall\n",
      "C: shop\n",
      "D: michigan\n",
      "E: large city\n",
      "\n",
      "PREDICTION:\n",
      "In large cities, there are a lot of delicatessens.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 15\n",
      "Correct answer: B (jail)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: If you get in a fight after getting drunk where are you likely to end up?\n",
      "choices: A: bar; B: jail; C: raise hell; D: liquor store; E: gutter\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: bar\n",
      "B: jail\n",
      "C: raise hell\n",
      "D: liquor store\n",
      "E: gutter\n",
      "\n",
      "PREDICTION:\n",
      "If you get in a fight after getting drunk, you are likely to end up in the gutter.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 16\n",
      "Correct answer: E (follow)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: When a teacher gives you a command what should you do?\n",
      "choices: A: question; B: ask; C: obey; D: serve; E: follow\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: question\n",
      "B: ask\n",
      "C: obey\n",
      "D: serve\n",
      "E: follow\n",
      "\n",
      "PREDICTION:\n",
      "When a teacher gives you a command, you should obey it.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 17\n",
      "Correct answer: A (going to jail)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: Someone charged with killing people is likely to reside where?\n",
      "choices: A: going to jail; B: terrible; C: murder; D: home; E: get arrested\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: going to jail\n",
      "B: terrible\n",
      "C: murder\n",
      "D: home\n",
      "E: get arrested\n",
      "\n",
      "PREDICTION:\n",
      "Prison is a place of confinement. Someone charged with killing people is likely to reside in a prison.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 18\n",
      "Correct answer: A (mistakes)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: Why does grooming require careful consideration.?\n",
      "choices: A: mistakes; B: neatness; C: errors; D: cleanliness; E: beauty\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: mistakes\n",
      "B: neatness\n",
      "C: errors\n",
      "D: cleanliness\n",
      "E: beauty\n",
      "\n",
      "PREDICTION:\n",
      "grooming is the act of grooming oneself. Grooming is the act of grooming oneself. Grooming is the act of grooming oneself. Grooming is the act of grooming oneself. Grooming is the act of grooming oneself. Grooming is the act of grooming oneself. Grooming is the act of grooming oneself. Grooming is the act of grooming oneself.\n",
      "\n",
      "================================================================================\n",
      "Wrong example 19\n",
      "Correct answer: B (colorado)\n",
      "Predicted: None\n",
      "WRONG ✗ \n",
      "\n",
      "INPUT:\n",
      "question: Where could you find a marmoset in a zoo?\n",
      "choices: A: rainforest; B: colorado; C: underground; D: dictionary; E: new york\n",
      "explain your answer:\n",
      "\n",
      "CHOICES:\n",
      "A: rainforest\n",
      "B: colorado\n",
      "C: underground\n",
      "D: dictionary\n",
      "E: new york\n",
      "\n",
      "PREDICTION:\n",
      "Marmosets are endemic to the Democratic Republic of the Congo. The Democratic Republic of the Congo is home to the largest population of Marmosets in the world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split into correct & wrong\n",
    "correct_list = [r for r in results if r[\"is_correct\"]]\n",
    "wrong_list   = [r for r in results if not r[\"is_correct\"]]\n",
    "\n",
    "print(f\"Correct: {len(correct_list)}  Wrong: {len(wrong_list)}\")\n",
    "\n",
    "letters = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "\n",
    "# ===============================\n",
    "# 1) PRINT CORRECT EXAMPLES\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\"*35 + \"  CORRECT EXAMPLES  \" + \"=\"*35)\n",
    "\n",
    "num_show = 20  # show up to 20\n",
    "\n",
    "for i, rec in enumerate(correct_list[:num_show]):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Correct example {i}\")\n",
    "    print(f\"Correct answer: {rec['correct_answer']} ({rec['correct_choice_text']})\")\n",
    "    print(f\"Predicted: {rec['predicted_answer']}\")\n",
    "    flag = \"(via gold text match)\" if rec.get(\"used_gold_text_match\", False) else \"\"\n",
    "    print(\"RIGHT ✓\", flag)\n",
    "\n",
    "    print(\"\\nINPUT:\")\n",
    "    print(rec[\"input_text\"])\n",
    "\n",
    "    # print choices\n",
    "    print(\"\\nCHOICES:\")\n",
    "    for idx, c in enumerate(rec[\"choices\"]):\n",
    "        print(f\"{letters[idx]}: {c}\")\n",
    "\n",
    "    print(\"\\nPREDICTION:\")\n",
    "    print(rec[\"prediction_text\"])\n",
    "    print()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 2) PRINT WRONG EXAMPLES\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\"*35 + \"  WRONG EXAMPLES  \" + \"=\"*35)\n",
    "\n",
    "for i, rec in enumerate(wrong_list[:num_show]):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Wrong example {i}\")\n",
    "    print(f\"Correct answer: {rec['correct_answer']} ({rec['correct_choice_text']})\")\n",
    "    print(f\"Predicted: {rec['predicted_answer']}\")\n",
    "    flag = \"(via gold text match)\" if rec.get(\"used_gold_text_match\", False) else \"\"\n",
    "    print(\"WRONG ✗\", flag)\n",
    "\n",
    "    print(\"\\nINPUT:\")\n",
    "    print(rec[\"input_text\"])\n",
    "\n",
    "    # print choices\n",
    "    print(\"\\nCHOICES:\")\n",
    "    for idx, c in enumerate(rec[\"choices\"]):\n",
    "        print(f\"{letters[idx]}: {c}\")\n",
    "\n",
    "    print(\"\\nPREDICTION:\")\n",
    "    print(rec[\"prediction_text\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94274d75-9ded-484d-9263-b81bed0a0ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      "C:\\Users\\yanch\\UOFTproject\\2025fall\n",
      "\n",
      "Files and folders in current directory:\n",
      "['.ipynb_checkpoints', '1513ass3.ipynb', '1513ass5.ipynb', '1513project.ipynb', 'build_loaders.py', 'build_loadersCopy1.py', 'cose_dev.jsonl', 'cose_dev_v1.0_NEW.jsonl', 'csqa_from_6000.csv', 'csqa_from_6000.jsonl', 'csqa_from_6000_3b.csv', 'csqa_from_6000_3b.jsonl', 'csqa_full_clean_v2.jsonl', 'error_log_from_6000.txt', 'error_log_from_6000_3b.txt', 'F25_APS1070_Project_1.ipynb', 'F25_APS1070_Project_2.ipynb', 'F25_APS1070_Project_3.1.ipynb', 'F25_APS1070_Project_3.ipynb', 'F25_APS1070_Project_4.ipynb', 'F25_Project_3_Part_1_git.ipynb', 'FLAN-T5.ipynb', 'flan_t5_base_csqa_lora_v2', 'flan_t5_base_csqa_lora_v4', 'flan_t5_large_csqa_lora_v1', 'flan_t5_lora_cose_v2', 'generate_csqa_from_6000.ipynb', 'HTRU_2.csv', 'Lastname_Firstname_Assgn2.ipynb', 'Lastname_Firstname_Assgn4.1.ipynb', 'Lastname_Firstname_Assgn4.ipynb', 'Lastname_Firstname_Assgn_3.1.ipynb', 'Lastname_Firstname_Assgn_3.ipynb', 'MNIST.ipynb', 'ozone_air_pollution_by_station.csv', 'ozone_clean_table.csv', 'T5.ipynb', 't5_lora_cose', 'train_t5_CoSE.ipynb', 'V3.ipynb', 'V4.ipynb', 'xai_outputs']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n",
    "\n",
    "print(\"\\nFiles and folders in current directory:\")\n",
    "print(os.listdir(\".\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a38c736-68c2-46cd-8e27-afaa079000ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "\n",
      "Loading base model: google/flan-t5-base\n",
      "Loading LoRA from: flan_t5_base_csqa_lora_v2/checkpoint-1461\n",
      "\n",
      "Loading base model: google/flan-t5-large\n",
      "Loading LoRA from: flan_t5_large_csqa_lora_v1/checkpoint-974\n",
      "\n",
      "================================================================================\n",
      "Model: flan_t5_base\n",
      "- Input:\n",
      "question:  Why would a person place a metal spoon in the neck of an opened champagne bottle before putting it back in the refrigerator?\n",
      "choices: A: To measure the temperature of the drink; B: To slow down the loss of carbonation; C: To prevent the bottle from freezing; D: To make the champagne taste sweeter; E: To stop the bottle from tipping over\n",
      "explain your answer:\n",
      "\n",
      "- Output:\n",
      "answer: E. Because a metal spoon is used to measure temperature of the champagne bottle before putting it back in the refrigerator.\n",
      "\n",
      "- Parsed answer letter: E\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Model: flan_t5_large\n",
      "- Input:\n",
      "question:  Why would a person place a metal spoon in the neck of an opened champagne bottle before putting it back in the refrigerator?\n",
      "choices: A: To measure the temperature of the drink; B: To slow down the loss of carbonation; C: To prevent the bottle from freezing; D: To make the champagne taste sweeter; E: To stop the bottle from tipping over\n",
      "explain your answer:\n",
      "\n",
      "- Output:\n",
      "In order to slow down the loss of carbonation, a metal spoon should be placed in the neck of an opened champagne bottle before putting it back in the refrigerator. The answer: B.\n",
      "\n",
      "- Parsed answer letter: B\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from peft import PeftModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ===========================================================\n",
    "# 1. The base names of the two models & LoRA checkpoint (using relative path)\n",
    "# ===========================================================\n",
    "\n",
    "CONFIGS = {\n",
    "    \"flan_t5_base\": {\n",
    "        \"base_model_name\": \"google/flan-t5-base\",\n",
    "        # Relative to the current working directory C:\\Users\\yanch\\UOFTproject\\2025fall\n",
    "        \"lora_path\": \"flan_t5_base_csqa_lora_v2/checkpoint-1461\",\n",
    "    },\n",
    "    \"flan_t5_large\": {\n",
    "        \"base_model_name\": \"google/flan-t5-large\",\n",
    "        \"lora_path\": \"flan_t5_large_csqa_lora_v1/checkpoint-974\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# ===========================================================\n",
    "# 2. Utility function: Construct input & Draw answer letters\n",
    "# ===========================================================\n",
    "\n",
    "LETTERS = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "def build_input(question, choices):\n",
    "    choice_str = \"; \".join(f\"{LETTERS[i]}: {choices[i]}\" for i in range(len(choices)))\n",
    "    return (\n",
    "        f\"question: {question}\\n\"\n",
    "        f\"choices: {choice_str}\\n\"\n",
    "        f\"explain your answer:\"\n",
    "    )\n",
    "\n",
    "def extract_answer_letter(text):\n",
    "    t = text.lower()\n",
    "    # the answer is C / answer is C / answer: C\n",
    "    m = re.search(r\"(?:the\\s+)?answer(?:\\s+is|[: ]+)\\s*([a-f])\", t)\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "    m2 = re.search(r\"answer[: ]*\\s*([a-f])\", t)\n",
    "    if m2:\n",
    "        return m2.group(1).upper()\n",
    "    return None\n",
    "\n",
    "def load_model(base_model_name, lora_path):\n",
    "    print(f\"\\nLoading base model: {base_model_name}\")\n",
    "    base = T5ForConditionalGeneration.from_pretrained(base_model_name).to(device)\n",
    "    print(f\"Loading LoRA from: {lora_path}\")\n",
    "    model = PeftModel.from_pretrained(base, lora_path).to(device)\n",
    "    tok = T5Tokenizer.from_pretrained(base_model_name)\n",
    "    model.eval()\n",
    "    return model, tok\n",
    "\n",
    "def run_one_model(model_name, model, tokenizer, question, choices):\n",
    "    input_text = build_input(question, choices)\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=384\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=96,\n",
    "            num_beams=4,\n",
    "            do_sample=False,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "    letter = extract_answer_letter(decoded)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"- Input:\")\n",
    "    print(input_text)\n",
    "    print(\"\\n- Output:\")\n",
    "    print(decoded)\n",
    "    print(f\"\\n- Parsed answer letter: {letter}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 3. Main program: Run two models for the same problem\n",
    "# ===========================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Change it here to the question and option you want to test\n",
    "    question = \" Why would a person place a metal spoon in the neck of an opened champagne bottle before putting it back in the refrigerator?\"\n",
    "    choices = [\n",
    "        \"To measure the temperature of the drink\",\n",
    "        \"To slow down the loss of carbonation\",\n",
    "        \"To prevent the bottle from freezing\",\n",
    "        \"To make the champagne taste sweeter\",\n",
    "        \"To stop the bottle from tipping over\",\n",
    "    ]\n",
    "\n",
    "    # First, load two models\n",
    "    models = {}\n",
    "    for name, cfg in CONFIGS.items():\n",
    "        model, tok = load_model(cfg[\"base_model_name\"], cfg[\"lora_path\"])\n",
    "        models[name] = (model, tok)\n",
    "\n",
    "    # the same question + choices，Run the two models in sequence\n",
    "    for name, (model, tok) in models.items():\n",
    "        run_one_model(name, model, tok, question, choices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8183392-b44e-4fd5-8e0f-d2f6437f0360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
